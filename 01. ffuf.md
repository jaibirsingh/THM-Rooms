# ffuf  --> To be completed
* ffuf stands for Fuzz Faster U Fool.
* It's a tool used for web enumeration, fuzzing and directory brute forcing.
* This is a common technique used in penetration testing or security assessments to discover hidden or non-linked web content that might be vulnerable or unintentionally exposed.

# Task 1 --> Basics
## Install ffuf
* Which Linux distributions have ffuf included by default?
  * BlackArch
  * Pentoo
  * Parrot
  * Kali
  * Repology
 
* What is Repology?
  * A service that monitors a lot of package repositories and other sources, and aggregates data on software packaging versions, reporting new releases and packaging problems

* If ffuf is not included by default, it can be installed using the following instructions: https://github.com/ffuf/ffuf#installation


## Install SecLists

### What is SecLists
* A collection of multiple types of lists used during security assessments

* **What are different types of lists**
  * Usernames, Passwords, URLs, sensitive data patterns, fuzzing payloads, web shells, etc.
 
* **It is already included in the following distributions**
  * BlackArch
  * Pentoo
  * Parrot
  * Kali
  * If not included: https://github.com/danielmiessler/SecLists#install
 
## Practical
* At a minimum we're required to supply two options: -u to specify an URL and -w to specify a wordlist. The default keyword FUZZ is used to tell ffuf where the wordlist entries will be injected. We can append it to the end of the URL like so:

* `ffuf -u http://10.10.122.16/FUZZ -w /usr/share/seclists/Discovery/Web-Content/big.txt`

* You could also use any custom keyword instead of FUZZ, you just need to define it like this wordlist.txt:KEYWORD.

* `ffuf -u http://10.10.122.16/NORAJ -w /usr/share/seclists/Discovery/Web-Content/big.txt:NORAJ`

***
# Task 2 --> Finding pages and directories
* One approach could be using generic files like: `raft-medium-files-lowercase.txt`
* However, using a large generic wordlist containing irrelevant file extensions is not very efficient.
* Other approach: We can assume that `index.[extension]` is the default page on most websites.:
* `ffuf -u http://[target]/indexFUZZ -w /usr/share/seclists/Discovery/Web-Content/web-extensions.txt`
* This command would find the matched extensions throughout the website. These extensions then can be sued in the following command:
 * `ffuf -u http[://[target]/FUZZ -w [path to "Web-Content/raft-medium-words-lowercase.txt"] -e [extensions found from the above command]`
* Then using these extensions:
 * `ffuf -u http://[target]/FUZZ -w [path to "Web-Content/raft-medium-files-lowercase.txt"] -e [extensions]`

# Task 3 --> Using filters
* By adding `-fc 403` (filter code) we'll hide from the output all 403
* if you know you want to see 200 status code responses, you could use `-mc 200` (match code) instead of having a long list of filtered codes.
* Unless we have a LFI (local file inclusion) this kind of files aren't interesting, so we can use -fs 0 (filter size).
* MATCHER OPTIONS:
 * -mc                 Match HTTP status codes, or "all" for everything. (default: 200,204,301,302,307,401,403,405)
 * -ml                 Match amount of lines in response
 * -mr                 Match regexp
 * -ms                 Match HTTP response size
 * -mw                 Match amount of words in response

* FILTER OPTIONS:
  * -fc                 Filter HTTP status codes from response. Comma separated list of codes and ranges
  * -fl                 Filter by amount of lines in response. Comma separated list of line counts and ranges
  * -fr                 Filter regexp
  * -fs                 Filter HTTP response size. Comma separated list of sizes and ranges
  * -fw                 Filter by amount of words in response. Comma separated list of word counts and ranges
